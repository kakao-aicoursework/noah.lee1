{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1092faf0-0064-4401-be63-fc0f7da30dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from utils.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe603ecc-9faa-4264-a3cd-b58049cd5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "776810d4-8657-4504-b545-8a09500998df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type 여",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOpenAI(temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m여름에 가면 좋을 해외 여행지 3곳 추천해줘\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mllm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/base.py:551\u001B[0m, in \u001B[0;36mBaseChatModel.__call__\u001B[0;34m(self, messages, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    544\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    545\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    546\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    549\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    550\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[0;32m--> 551\u001B[0m     generation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    552\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    553\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(generation, ChatGeneration):\n\u001B[1;32m    555\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m generation\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/base.py:309\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[1;32m    308\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e)\n\u001B[0;32m--> 309\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    310\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    311\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[1;32m    313\u001B[0m ]\n\u001B[1;32m    314\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/base.py:299\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    298\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 299\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m         )\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/base.py:446\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    443\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    444\u001B[0m     )\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported:\n\u001B[0;32m--> 446\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/openai.py:337\u001B[0m, in \u001B[0;36mChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001B[0m\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m generation \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatResult(generations\u001B[38;5;241m=\u001B[39m[generation])\n\u001B[0;32m--> 337\u001B[0m message_dicts, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_message_dicts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs}\n\u001B[1;32m    339\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompletion_with_retry(\n\u001B[1;32m    340\u001B[0m     messages\u001B[38;5;241m=\u001B[39mmessage_dicts, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    341\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/openai.py:352\u001B[0m, in \u001B[0;36mChatOpenAI._create_message_dicts\u001B[0;34m(self, messages, stop)\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`stop` found in both the input and default params.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    351\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m stop\n\u001B[0;32m--> 352\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m [convert_message_to_dict(m) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages]\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m message_dicts, params\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/chat_models/openai.py:352\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`stop` found in both the input and default params.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    351\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m stop\n\u001B[0;32m--> 352\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m [\u001B[43mconvert_message_to_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages]\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m message_dicts, params\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/gpt_app/lib/python3.9/site-packages/langchain/adapters/openai.py:83\u001B[0m, in \u001B[0;36mconvert_message_to_dict\u001B[0;34m(message)\u001B[0m\n\u001B[1;32m     77\u001B[0m     message_dict \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     78\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: message\u001B[38;5;241m.\u001B[39mcontent,\n\u001B[1;32m     80\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: message\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m     81\u001B[0m     }\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 83\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot unknown type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m message\u001B[38;5;241m.\u001B[39madditional_kwargs:\n\u001B[1;32m     85\u001B[0m     message_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39madditional_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[0;31mTypeError\u001B[0m: Got unknown type 여"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\")\n",
    "text = \"여름에 가면 좋을 해외 여행지 3곳 추천해줘\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "008a5849-3c47-4e95-a88c-f9a4844e55ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents = [i for i in read_template(\"template/kakaosync.txt\").split(\"<EOS>\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "245b0d0e-a88f-4a64-a469-655bff06886c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89cbaccc-1734-40f3-b229-da0e692bf7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<시작하기>\\n이 문서는 카카오싱크에 대해 소개하고, 카카오싱크 도입에 필요한 검수 및 설정에 대해 안내합니다.\\n</시작하기>\\n<EOS>\\n\\n<기능 소개>\\n카카오싱크는 소셜 로그인인 카카오 로그인을 통해 보다 편리하게 서비스에 가입할 수 있도록 도와주는 비즈니스 설루션입니다. 카카오싱크가 제공하는 핵심 기능은 다음 두 가지입니다.\\n\\n  기능 | 설명 | 효과\\n  간편가입 | 동의 화면에서 서비스 약관까지 한 번에 동의받을 수 있습니다. | 서비스 약관 동의 절차 생략 가능\\n   더 다양한 사용자 정보 활용 | 서비스 회원 가입 시 필요한 다양한 사용자 정보를 제공받을 수 있습니다. 이름, 이메일, 전화번호, 연령대, 생일, 성별, 출생�'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncate_text(read_template(\"template/kakaosync.txt\"), max_tokens=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4f1560c-95ca-4266-955b-48aaf53296ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카카오싱크는 카카오 로그인을 통해 간단하게 회원 가입할 수 있는 기능입니다. 카카오싱크를 사용하려면 카카오비즈니스 관리자센터에서 카카오싱크를 신청하고 검수를 받아야 합니다. 검수 완료 후 필요한 설정을 완료하면 카카오싱크를 사용할 수 있습니다.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template=f\"\"\"\n",
    "당신은 카카오싱크에서 도움말을 주는 챗봇입니다.\n",
    "챗봇 가이드라인은 다음과 같습니다.\n",
    "{truncate_text(read_template(\"template/kakaosync.txt\"), max_tokens=4000)}\n",
    "다음 규칙에 맞게 답변하세요.\n",
    "- 3줄로 요약해서 답변하세요\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo-16k\")\n",
    "chain.run(\"사용하는 방법 설명해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cddf92c-76ab-4443-8bce-a6b1d54ab30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
